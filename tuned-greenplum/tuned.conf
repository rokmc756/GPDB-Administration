[main]
summary=Optimize for Greenplum MPP Database
include=throughput-performance
# include=${f:virt_check:virtual-guest:throughput-performance}

[bootloader]
cmdline=net.ifnames=0 biosdevname=0

[cpu]
force_latency=1
governor=performance
energy_perf_bias=performance
min_perf_pct=100

[disk]
readahead=>16384
elevator=mq-deadline               # For RHEL 8.x, deadline is for 7.x

# udevadm info --query=property --name=/dev/device | grep -E '(WWN|SERIAL)'
# devices_udev_regex=IDNAME=device system unique id
# Comma separated list of devices, all devices if commented out.
# devices=sda

[vm]
transparent_hugepages=never

# [irqbalance]
# banned_cpus=2,4,9-13

# [selinux] # In case of enabling SELinux
# avc_cache_threshold=65536

[scheduler]
# ktune sysctl settings for rhel6 servers, maximizing i/o throughput
# Minimal preemption granularity for CPU-bound tasks:
# (default: 1 msec#  (1 + ilog(ncpus)), units: nanoseconds)
sched_min_granularity_ns = 10000000

# The total time the scheduler will consider a migrated process
# "cache hot" and thus less likely to be re-migrated
# (system default is 500000, i.e. 0.5 ms)
sched_migration_cost_ns = 50000000

[net]
# List of coalescing parameters of your all network device, use `ethtool -c device`.
# This parameter are not supporetd by all network cards.
coalesce=rx-usecs 3 tx-usecs 16

# Allow changing the offload parameters and other features for the specified network devices.
# Query the features of your network device, use `ethtool -k device`.
features=tx off gso off gro off

# Allows changing the pause parameters for the specified network devices.
# Query the pause parameters of your network device, use `ethtool -a device`.
pause=autoneg off

# To query the ring parameters of your network device, use `ethtool -g device`
ring=rx 1024 tx 512

# Allows changing the numbers of channels for the specified network device.
# A channel is an IRQ and the set of queues that can trigger that IRQ.
# To query the channels parameters of your network device, use `ethtool -l device`.
channels=combined 16

# Sets the size of the hash table which stores lists of conntrack entries by writing to
# `/sys/module/nf_conntrack/parameters/hashsize`
# nf_conntrack_hashsize=1048576

[sysctl]
kernel.shmall=${f:exec:$(expr $(getconf _PHYS_PAGES) / 2)}
kernel.shmmax=${f:exec:$(expr $(getconf _PHYS_PAGES) / 2 \* $(getconf PAGE_SIZE))}
kernel.shmmni = 4096
kernel.sem = 250 2048000 200 8192
kernel.sysrq = 1
kernel.core_uses_pid = 1
kernel.msgmnb = 65536
kernel.msgmax = 65536
kernel.msgmni = 2048
net.ipv4.tcp_syncookies = 1
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.tcp_max_syn_backlog = 4096
net.ipv4.conf.all.arp_filter = 1
net.ipv4.ipfrag_high_thresh = 41943040
net.ipv4.ipfrag_low_thresh = 31457280
net.ipv4.ipfrag_time = 60
net.core.netdev_max_backlog = 10000
net.core.rmem_max = 2097152
net.core.wmem_max = 2097152
vm.swappiness = 10
vm.zone_reclaim_mode = 0

# For optimal performance of checkpoint writer.
vm.dirty_expire_centisecs = 500
vm.dirty_writeback_centisecs = 100
vm.dirty_background_bytes = 1610612736
vm.dirty_bytes = 4294967296
vm.dirty_ratio = 0
# The generator of dirty data starts writeback at this percentage (system default is 20%)
# vm.dirty_ratio = 30

# For core dump
kernel.core_pattern=/var/core/core.%h.%t

# vm.overcommit_memory = 2 # See Segment Host Memory
# vm.overcommit_ratio = 95 # See Segment Host Memory
# net.ipv4.ip_local_port_range = 10000 65535 # See Port Settings
# vm.dirty_background_ratio = 0 # See System Memory
# If a workload mostly uses anonymous memory and it hits this limit, the entire
# working set is buffered for I/O, and any more write buffering would require
# swapping, so it's time to throttle writes until I/O can catch up.  Workloads
# that mostly use file mappings may be able to use even higher values.
#

[service]
service.sshd=start,enable,file:${i:PROFILE_DIR}/sshd.conf
service.chronyd=start,enable,file:${i:PROFILE_DIR}/chrony.conf
service.firewalld=stop,disable

# Ignore corrected errors and associated scans that cause latency spikes
[sysfs]
/sys/devices/system/machinecheck/machinecheck*/ignore_ce=1

# Allows setting CPUAffinity in `/etc/systemd/system.conf`. It configures the CPU affinity for the service manager
# as well as the default CPU affinity for all forked off processes.
# [systemd]
# cpu_affinity=0-3

# Sets various powersave levels on video cards. Currently, only the Radeon cards are supported.
# NOTE: This plug-in is experimental and the option might change in future releases.
# To set the powersave level for the Radeon video card to high
# [video]
# radeon_powersave=high

[script]
# priority=5
# script=/etc/tuned/greenplum/sysctl-greenplum.sh - OK
script=${i:PROFILE_DIR}/sysctl-greenplum.sh

